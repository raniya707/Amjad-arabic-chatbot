# -*- coding: utf-8 -*-
"""THE Amjadbot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fdihfg57hMaLdzVObrokDtOyBR934EJN
"""

import pandas as pd
import nltk as nltk

emotions = pd.read_csv('/content/arabic2.txt',sep=',',header=None)
emotions.columns=['emotions','text','response']
emotions.head()

emotions.describe()

emotions.isnull().value_counts()

import string
string.punctuation

def remove_punct(text):
  remove_punct1="".join([word for word in text if word not in string.punctuation])
  return remove_punct1

emotions['text_without_punc']= emotions['text'].apply(lambda x: remove_punct(x))
emotions['response_without_punc']= emotions['response'].apply(lambda x: remove_punct(x))
emotions.head()

import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

stopwords_Ar= nltk.corpus.stopwords.words('arabic')

stopwords_Ar

from nltk import word_tokenize
nltk.download('punkt')
def remove_stopwords(text):
  wordss=word_tokenize(text)
  filterd_words=[word for word in wordss if word not in stopwords_Ar]
  filterd_text=" ".join(filterd_words)
  return filterd_text

emotions['text_without_stopwords']= emotions['text_without_punc'].apply(lambda x: remove_stopwords(x))
emotions.head()

!pip install qalsadi

import qalsadi.lemmatizer

from nltk import word_tokenize
nltk.download('punkt')
def lemtaization(text):
    lemmer = qalsadi.lemmatizer.Lemmatizer()
    wordss=word_tokenize(text)
    filterd_words=[lemmer.lemmatize(token) for token in wordss]
    filterd_text=" ".join(filterd_words)
    return filterd_text

emotions['text lemtaization']= emotions['text_without_stopwords'].apply(lambda x: lemtaization(x))
emotions.head()

from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd
vectorizer = CountVectorizer(ngram_range=(1,3))
features_cv = vectorizer.fit_transform(emotions['text_without_stopwords'])
print(features_cv.shape)
print(features_cv)

features_cv=pd.DataFrame(features_cv.toarray())
features_cv.columns = vectorizer.get_feature_names_out()
features_cv

re=emotions['response_without_punc']

from sklearn.model_selection import train_test_split
X_train , X_test , y_train , y_test =train_test_split(features_cv,re,test_size=0.25)

from sklearn.naive_bayes import MultinomialNB
clf=MultinomialNB()
clf.fit(features_cv,re)

end=["الى اللقاء","وداعا","مع السلامة","لا اريد التحدث"]

new_sentence = input("مرحبا أنا المتحدث الالي امجد:")
new_x=vectorizer.transform([new_sentence])
p=clf.predict(new_x)
print(p)
while True:
    new_sentence = input()
    new_x=vectorizer.transform([new_sentence])
    p=clf.predict(new_x)
    if  new_sentence in end:
        print('حسنا الى اللقاء')
        break
    else:
      print("amjad ->",p)

clf.score(X_test,y_test)